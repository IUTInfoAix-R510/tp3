# <img src="https://raw.githubusercontent.com/IUTInfoAix-R510/Syllabus/main/assets/logo.png" alt="class logo" class="logo"/> R5.Real.10 - Nouveaux paradigmes de base de donn√©es

### IUT d‚ÄôAix-Marseille ‚Äì D√©partement Informatique Aix-en-Provence

* **Ressource:** [R5.Real.10](https://cache.media.enseignementsup-recherche.gouv.fr/file/SPE4-MESRI-17-6-2021/35/5/Annexe_17_INFO_BUT_annee_1_1411355.pdf)
* **Responsables:**
  * [S√©bastien Nedjar](mailto:sebastien.nedjar@univ-amu.fr)
* **Besoin d'aide ?**
  * Consulter et/ou cr√©er des [issues](https://github.com/IUTInfoAix-R510/Cours/issues).
  * [Email](mailto:sebastien.nedjar@univ-amu.fr) pour une question d'ordre priv√©e, ou pour convenir d'un rendez-vous physique.

# Travaux pratiques R5.Real.10 - Mod√©lisation avanc√©e et patterns de conception MongoDB (4h)

## üéØ Objectifs de la s√©ance

### Objectifs p√©dagogiques
√Ä l'issue de cette s√©ance, vous serez capable de :
- **Choisir** entre embedding et r√©f√©rencement selon le cas d'usage
- **Appliquer** les patterns de mod√©lisation MongoDB (Subset, Computed, Bucket, etc.)
- **Optimiser** les mod√®les pour les performances et la scalabilit√©
- **Concevoir** des sch√©mas pour des applications IoT temps r√©el
- **Impl√©menter** des patterns avanc√©s (versioning, archiving, CQRS)

### Lien avec le projet fil rouge
Cette s√©ance est **cruciale** pour votre projet :
- Pattern **Bucket** pour les s√©ries temporelles de capteurs
- Pattern **Computed** pour les statistiques pr√©-calcul√©es
- Pattern **Outlier** pour les pics de donn√©es
- Architecture **CQRS** pour s√©parer lecture/√©criture

### Pr√©requis
- TP1 et TP2 compl√©t√©s
- Compr√©hension des pipelines d'agr√©gation
- MongoDB Atlas configur√© et accessible

---

## üìö Phase 1 : Les fondamentaux de la mod√©lisation MongoDB (45 min)

### Embedding vs R√©f√©rencement

En MongoDB, vous avez deux grandes strat√©gies pour mod√©liser les relations entre donn√©es :

#### üîó Embedding (Imbrication)

L'**embedding** consiste √† stocker les donn√©es li√©es **dans le m√™me document**.

```javascript
// ‚úÖ EMBEDDING : L'adresse est DANS le document utilisateur
{
    _id: "user123",
    name: "Alice Martin",
    email: "alice@example.com",
    address: {                    // ‚Üê Donn√©es imbriqu√©es
        street: "123 Rue de la Paix",
        city: "Aix-en-Provence",
        zipcode: "13100"
    }
}
```

**Avantages** : Une seule requ√™te pour tout r√©cup√©rer, donn√©es atomiques, pas de jointure.

**Inconv√©nients** : Duplication de donn√©es, limite 16MB par document, mise √† jour plus complexe.

#### üîÄ R√©f√©rencement

Le **r√©f√©rencement** consiste √† stocker les donn√©es dans des **documents s√©par√©s** reli√©s par un identifiant.

```javascript
// ‚úÖ R√âF√âRENCEMENT : L'adresse est dans une collection s√©par√©e

// Collection users
{
    _id: "user123",
    name: "Alice Martin",
    email: "alice@example.com",
    address_id: "addr456"         // ‚Üê R√©f√©rence vers l'autre document
}

// Collection addresses
{
    _id: "addr456",
    street: "123 Rue de la Paix",
    city: "Aix-en-Provence",
    zipcode: "13100"
}
```

**Avantages** : Pas de duplication, donn√©es partageables, pas de limite de taille.

**Inconv√©nients** : N√©cessite plusieurs requ√™tes ou `$lookup`, pas de transaction atomique native.

#### Le spectre de la mod√©lisation

En r√©alit√©, ce n'est pas un choix binaire. Il existe un **spectre** d'options :

```mermaid
graph LR
    A[Embedding<br/>Complet] --> B[Embedding<br/>Partiel]
    B --> C[Hybride]
    C --> D[R√©f√©rences<br/>avec Cache]
    D --> E[R√©f√©rences<br/>Pures]

    style A fill:#4CAF50,color:#fff
    style E fill:#f44336,color:#fff
```

| Approche | Description | Exemple |
|----------|-------------|---------|
| **Embedding complet** | Toutes les donn√©es li√©es dans le document | User + toutes ses commandes |
| **Embedding partiel** | Seulement un sous-ensemble utile | User + 5 derni√®res commandes |
| **Hybride** | Mix des deux selon le contexte | User + r√©sum√© commandes + ref vers d√©tails |
| **R√©f√©rences avec cache** | R√©f√©rence + copie des champs fr√©quents | Commande + {user_id, user_name} |
| **R√©f√©rences pures** | Uniquement les IDs, comme en SQL | Commande + user_id seul |

#### Tableau r√©capitulatif

| Crit√®re | Embedding | R√©f√©rencement |
|---------|-----------|---------------|
| **Lecture** | 1 requ√™te | Plusieurs requ√™tes ou $lookup |
| **√âcriture** | Mise √† jour document entier | Mise √† jour cibl√©e |
| **Duplication** | Possible | √âvit√©e |
| **Taille max** | 16 MB par document | Illimit√©e |
| **Atomicit√©** | Garantie (m√™me document) | Requiert transaction |
| **Cas d'usage** | Donn√©es lues ensemble | Donn√©es ind√©pendantes |

### Les facteurs de d√©cision

#### La matrice de d√©cision

Pour chaque relation, posez-vous ces questions :

| Question | ‚Üí Embedding | ‚Üí R√©f√©rencement |
|----------|-------------|-----------------|
| **Cardinalit√© ?** | 1:1 ou 1:few (< 20) | 1:many ou N:N |
| **Lus ensemble ?** | Oui, presque toujours | Non, souvent s√©par√©ment |
| **Taille born√©e ?** | Oui, croissance limit√©e | Non, peut cro√Ætre ind√©finiment |
| **Fr√©quence de mise √† jour ?** | Rarement modifi√© | Souvent modifi√© |
| **Besoin d'acc√®s ind√©pendant ?** | Non | Oui, requ√™tes s√©par√©es |

**R√®gle simple :** Si vous avez plus de trois r√©ponses dans la colonne "R√©f√©rencement", privil√©giez les r√©f√©rences.

### Exercices

Ces exercices vous permettent de pratiquer le choix entre embedding et r√©f√©rencement **avant** d'apprendre les patterns avanc√©s.

#### Exercice 1 : Blog - Auteur et Articles ‚≠ê‚òÜ‚òÜ

**Contexte :** Un blog simple o√π chaque article a un seul auteur.

**Question :** Faut-il embarquer l'auteur dans l'article ou cr√©er une r√©f√©rence ?

**Informations :**
- Un auteur √©crit en moyenne 50 articles
- On affiche toujours le nom et avatar de l'auteur avec l'article
- Le profil auteur (bio, liens sociaux) est rarement consult√©

```javascript
// Analysez et proposez votre mod√©lisation :

```

<details>
<summary>üí° Solution</summary>

```javascript
// ‚úÖ SOLUTION : Embedding partiel (donn√©es fr√©quentes) + R√©f√©rence (donn√©es compl√®tes)

// Collection articles
{
    _id: ObjectId("..."),
    title: "Introduction √† MongoDB",
    content: "...",
    published_at: ISODate("2024-01-15"),

    // Embedding partiel : seulement les infos affich√©es avec l'article
    author: {
        _id: ObjectId("author123"),
        name: "Alice Martin",
        avatar: "https://example.com/alice.jpg"
    }
}

// Collection authors (pour le profil complet)
{
    _id: ObjectId("author123"),
    name: "Alice Martin",
    avatar: "https://example.com/alice.jpg",
    bio: "D√©veloppeuse passionn√©e...",
    social_links: {
        twitter: "@alice_dev",
        github: "alice-martin"
    },
    created_at: ISODate("2023-01-01")
}
```

**Pourquoi ?**
- **Embedding partiel** : On √©vite un `$lookup` pour chaque article affich√©
- **R√©f√©rence** : Le profil complet reste accessible via `author._id`
- **Duplication limit√©e** : Seulement 2 champs (nom + avatar) sont dupliqu√©s
- **Mise √† jour** : Si l'auteur change d'avatar, il faut mettre √† jour les articles (acceptable car rare)

</details>

---

#### Exercice 2 : Commande et Produits ‚≠ê‚òÜ‚òÜ

**Contexte :** Un site e-commerce avec des commandes contenant plusieurs produits.

**Question :** Comment mod√©liser la relation commande ‚Üî produits ?

**Informations :**
- Une commande contient 1 √† 10 produits
- Le prix d'un produit peut changer apr√®s la commande
- On doit garder le prix au moment de l'achat

```javascript
// Analysez et proposez votre mod√©lisation :

```

<details>
<summary>üí° Solution</summary>

```javascript
// ‚úÖ SOLUTION : Embedding complet des lignes de commande

// Collection orders
{
    _id: ObjectId("..."),
    user_id: ObjectId("user123"),
    created_at: ISODate("2024-01-15"),
    status: "delivered",

    // Embedding complet : snapshot des produits au moment de l'achat
    items: [
        {
            product_id: ObjectId("prod456"),
            name: "Clavier m√©canique",        // Copie du nom
            price_at_purchase: 89.99,         // Prix fig√© !
            quantity: 1,
            subtotal: 89.99
        },
        {
            product_id: ObjectId("prod789"),
            name: "Souris gaming",
            price_at_purchase: 49.99,
            quantity: 2,
            subtotal: 99.98
        }
    ],

    total: 189.97,
    shipping_address: { /* ... */ }
}

// Collection products (catalogue actuel)
{
    _id: ObjectId("prod456"),
    name: "Clavier m√©canique",
    price: 99.99,  // Prix actuel (peut avoir chang√© !)
    stock: 45
}
```

**Pourquoi embedding complet ?**
- **Historique** : Le prix au moment de l'achat ne doit JAMAIS changer
- **Autonomie** : La commande est un "snapshot" complet, ind√©pendant du catalogue
- **Cardinalit√© faible** : 1-10 produits par commande = taille ma√Ætris√©e
- **Lecture atomique** : Une seule requ√™te pour afficher la commande

**‚ö†Ô∏è Anti-pattern** : Stocker uniquement `product_id` et faire un `$lookup` perdrait le prix historique !

</details>

---

#### Exercice 3 : Utilisateur et Adresses ‚≠ê‚≠ê‚òÜ

**Contexte :** Un utilisateur peut avoir plusieurs adresses de livraison.

**Question :** Embedding ou r√©f√©rencement pour les adresses ?

**Informations :**
- Un utilisateur a entre 1 et 5 adresses
- Les adresses sont toujours lues avec l'utilisateur (page profil, checkout)
- Une adresse appartient √† un seul utilisateur

```javascript
// Analysez et proposez votre mod√©lisation :

```

<details>
<summary>üí° Solution</summary>

```javascript
// ‚úÖ SOLUTION : Embedding complet

// Collection users
{
    _id: ObjectId("user123"),
    email: "alice@example.com",
    name: "Alice Martin",

    // Embedding : les adresses sont dans le document utilisateur
    addresses: [
        {
            _id: ObjectId("addr1"),
            label: "Domicile",
            street: "123 Rue de la Paix",
            city: "Aix-en-Provence",
            zipcode: "13100",
            is_default: true
        },
        {
            _id: ObjectId("addr2"),
            label: "Bureau",
            street: "45 Avenue des Champs",
            city: "Marseille",
            zipcode: "13001",
            is_default: false
        }
    ]
}
```

**Pourquoi embedding complet ?**
- **Cardinalit√© limit√©e** : Max 5 adresses = taille document ma√Ætris√©e
- **Toujours ensemble** : Adresses lues avec l'utilisateur (profil, checkout)
- **Propri√©t√© exclusive** : Une adresse n'est pas partag√©e entre utilisateurs
- **Atomicit√©** : Ajout/suppression d'adresse = une seule op√©ration

**Quand r√©f√©rencer √† la place ?**
- Si les adresses √©taient partag√©es entre utilisateurs (ex: adresse entreprise)
- Si on avait besoin de requ√™ter les adresses ind√©pendamment

</details>

---

#### Exercice 4 : Cours et √âtudiants ‚≠ê‚≠ê‚òÜ

**Contexte :** Une plateforme de formation avec des cours et des √©tudiants.

**Question :** Comment mod√©liser la relation N:N entre cours et √©tudiants ?

**Informations :**
- Un √©tudiant peut suivre 5-20 cours
- Un cours peut avoir 10-500 √©tudiants
- On veut afficher "Mes cours" pour un √©tudiant et "Liste des inscrits" pour un cours

```javascript
// Analysez et proposez votre mod√©lisation :

```

<details>
<summary>üí° Solution</summary>

```javascript
// ‚úÖ SOLUTION : R√©f√©rences des deux c√¥t√©s (relation N:N)

// Collection students
{
    _id: ObjectId("student123"),
    name: "Bob Dupont",
    email: "bob@example.com",

    // Liste des cours suivis (IDs seulement)
    enrolled_courses: [
        ObjectId("course1"),
        ObjectId("course2"),
        ObjectId("course3")
    ]  // Max ~20 IDs = taille acceptable
}

// Collection courses
{
    _id: ObjectId("course1"),
    title: "MongoDB Avanc√©",
    instructor: "Prof. Martin",

    // Compteur (pas la liste compl√®te !)
    student_count: 127

    // ‚ö†Ô∏è PAS de tableau enrolled_students ici (pourrait avoir 500 √©tudiants !)
}

// Collection enrollments (table de liaison)
{
    _id: ObjectId("..."),
    student_id: ObjectId("student123"),
    course_id: ObjectId("course1"),
    enrolled_at: ISODate("2024-01-10"),
    progress: 45,  // % de progression
    grade: null    // Note finale
}
```

**Pourquoi cette structure ?**

| Besoin | Solution | Requ√™te |
|--------|----------|---------|
| "Mes cours" (√©tudiant) | IDs dans `enrolled_courses` | `db.courses.find({_id: {$in: student.enrolled_courses}})` |
| "Liste inscrits" (cours) | Collection `enrollments` | `db.enrollments.find({course_id: X})` |
| Infos inscription | Collection `enrollments` | Progression, notes, date |

**R√®gle pour N:N :**
- **C√¥t√© "few"** (√©tudiant ‚Üí cours) : Embedding des IDs acceptable
- **C√¥t√© "many"** (cours ‚Üí √©tudiants) : R√©f√©rencement obligatoire
- **Donn√©es de liaison** (progression, notes) : Collection interm√©diaire

</details>

---

#### Exercice 5 : Quiz r√©capitulatif ‚≠ê‚òÜ‚òÜ

Pour chaque situation, indiquez **Embedding** ou **R√©f√©rencement** et justifiez en une phrase :

| # | Situation | Votre choix | Justification |
|---|-----------|-------------|---------------|
| 1 | Tags d'un article (5-10 tags) | | |
| 2 | Commentaires d'une vid√©o YouTube (milliers) | | |
| 3 | Ingr√©dients d'une recette (10-30) | | |
| 4 | Followers d'un compte Twitter (millions) | | |
| 5 | Coordonn√©es GPS d'un capteur IoT | | |

<details>
<summary>üí° R√©ponses</summary>

| # | Situation | Choix | Justification |
|---|-----------|-------|---------------|
| 1 | Tags d'un article | **Embedding** | Cardinalit√© faible (5-10), toujours lus ensemble, donn√©es simples |
| 2 | Commentaires YouTube | **R√©f√©rencement** | Cardinalit√© illimit√©e, pagination n√©cessaire, croissance non born√©e |
| 3 | Ingr√©dients recette | **Embedding** | Cardinalit√© born√©e, toujours lus ensemble, ne changent jamais apr√®s cr√©ation |
| 4 | Followers Twitter | **R√©f√©rencement** | Cardinalit√© potentiellement √©norme (millions), jamais affich√©s tous ensemble |
| 5 | Coordonn√©es GPS capteur | **Embedding** | Relation 1:1, donn√©es toujours lues ensemble, ne prennent pas de place |

**R√®gle m√©mo :**
- **Few** (1-100) ‚Üí Embedding probable
- **Many** (100-10000) ‚Üí √áa d√©pend du contexte
- **Unbounded** (illimit√©) ‚Üí R√©f√©rencement obligatoire

</details>

---

## üé® Phase 2 : Les Design Patterns MongoDB (75 min)

### Pattern : Subset (Sous-ensemble)

**Probl√®me :** Document avec un tableau qui peut devenir tr√®s large.

**Solution :** Garder seulement un subset pertinent dans le document principal.

```javascript
// ‚ùå Anti-pattern : Tous les followers dans le user
{
    _id: "user123",
    username: "alice",
    followers: [/* Potentiellement des millions! */]
}

// ‚úÖ Pattern Subset
{
    _id: "user123",
    username: "alice",
    follower_count: 1250000,
    recent_followers: [
        // Les 20 derniers seulement
        {user_id: "u456", date: ISODate("..."), username: "bob"},
        // ...
    ]
}

// Collection s√©par√©e pour tous les followers
{
    _id: ObjectId(),
    user_id: "user123",
    follower_id: "u456",
    date: ISODate("...")
}
```

### Pattern : Computed (Pr√©-calcul√©)

**Probl√®me :** Calculs co√ªteux r√©p√©t√©s fr√©quemment.

**Solution :** Pr√©-calculer et stocker les r√©sultats.

```javascript
// ‚ùå Anti-pattern : Calculer √† chaque fois
db.orders.aggregate([
    {$match: {user_id: "u123"}},
    {$group: {_id: null, total_spent: {$sum: "$amount"}}}
])

// ‚úÖ Pattern Computed
{
    _id: "u123",
    username: "alice",
    // Statistiques pr√©-calcul√©es
    stats: {
        total_orders: 156,
        total_spent: 12543.67,
        average_order: 80.41,
        last_order_date: ISODate("2024-01-15"),
        lifetime_value_score: 0.89,
        updated_at: ISODate("2024-01-15T10:00:00Z")
    }
}

// Mise √† jour incr√©mentale
db.users.updateOne(
    {_id: "u123"},
    {
        $inc: {
            "stats.total_orders": 1,
            "stats.total_spent": 99.99
        },
        $set: {
            "stats.last_order_date": new Date(),
            "stats.updated_at": new Date()
        }
    }
)
```

### Pattern : Bucket (Seau) pour Time-Series

**Probl√®me :** Millions de points de donn√©es temporelles.

**Solution :** Grouper par tranches de temps.

```javascript
// ‚ùå Anti-pattern : Un document par mesure
{
    sensor_id: "SENS-001",
    timestamp: ISODate("2024-01-15T10:05:00Z"),
    temperature: 22.5
}
// ‚Üí 288 documents/jour/capteur !

// ‚úÖ Pattern Bucket : Un document par heure
{
    _id: ObjectId(),
    sensor_id: "SENS-001",
    bucket_hour: ISODate("2024-01-15T10:00:00Z"),
    
    // Tableau de mesures (12 par heure si toutes les 5 min)
    measurements: [
        {t: 0, temp: 22.5, hum: 45.2},    // t=0 : 10:00
        {t: 5, temp: 22.6, hum: 45.1},    // t=5 : 10:05
        {t: 10, temp: 22.4, hum: 45.3},   // t=10: 10:10
        // ...
    ],
    
    // Statistiques pr√©-calcul√©es pour la p√©riode
    stats: {
        count: 12,
        temperature: {min: 22.1, max: 23.2, avg: 22.5},
        humidity: {min: 44.8, max: 46.1, avg: 45.2}
    }
}
// ‚Üí 24 documents/jour/capteur (r√©duction 12x)
```

### Pattern : Attribute (Attribut)

**Probl√®me :** Sch√©ma avec nombreux champs optionnels et vari√©s.

**Solution :** Transformer les champs en tableau d'attributs.

```javascript
// ‚ùå Anti-pattern : Centaines de champs possibles
{
    sku: "PROD-123",
    color: "red",
    size: "XL",
    material: "cotton",
    weight: 250,
    waterproof: true,
    // ... potentiellement des centaines d'attributs
}

// ‚úÖ Pattern Attribute
{
    sku: "PROD-123",
    // Attributs sous forme de tableau
    attributes: [
        {k: "color", v: "red", type: "string"},
        {k: "size", v: "XL", type: "string"},
        {k: "weight", v: 250, type: "number", unit: "g"},
        {k: "waterproof", v: true, type: "boolean"}
    ]
}

// Index pour recherche efficace
db.products.createIndex({"attributes.k": 1, "attributes.v": 1})

// Requ√™te
db.products.find({
    attributes: {
        $all: [
            {$elemMatch: {k: "color", v: "red"}},
            {$elemMatch: {k: "size", v: "XL"}}
        ]
    }
})
```

### Pattern : Outlier (Valeur aberrante)

**Probl√®me :** Quelques documents avec tableaux √©normes, la majorit√© petits.

**Solution :** Traiter diff√©remment les outliers.

```javascript
// Cas : Un post viral avec 100k commentaires vs posts normaux avec <100

// ‚úÖ Document normal
{
    _id: "post123",
    content: "Hello World",
    has_overflow: false,
    comments: [
        // Tous les commentaires (<100)
        {id: 1, text: "Nice!", user: "bob"},
        // ...
    ]
}

// ‚úÖ Document outlier
{
    _id: "post456",
    content: "Post viral!",
    has_overflow: true,  // Flag indiquant overflow
    comment_count: 100000,
    comments: [
        // Seulement les 50 derniers
        {id: 99951, text: "...", user: "..."},
        // ...
    ]
}

// Collection overflow pour les commentaires suppl√©mentaires
{
    post_id: "post456",
    bucket: 1,  // Bucket 1 = commentaires 51-1000
    comments: [/*...*/]
}
```

### Exercices guid√©s sur les patterns

Ces exercices sont con√ßus pour √™tre r√©alis√©s **sur machine**, pas √† pas. Chaque exercice vous guide progressivement vers la d√©couverte et l'application d'un pattern.

---

#### Exercice 6 : D√©couvrir le probl√®me des tableaux illimit√©s ‚≠ê‚òÜ‚òÜ

**Objectif :** Comprendre pourquoi on a besoin du Pattern Subset.

**√âtape 1 : Cr√©er un post avec beaucoup de commentaires**

Ex√©cutez ces commandes dans mongosh :

```javascript
// Nettoyer et cr√©er la collection
db.posts_v1.drop()

// Cr√©er un post avec 500 commentaires (simulation)
const comments = []
for (let i = 0; i < 500; i++) {
    comments.push({
        user: `user_${i % 50}`,
        text: `Ceci est le commentaire num√©ro ${i}. Lorem ipsum dolor sit amet.`,
        date: new Date(Date.now() - i * 60000)
    })
}

db.posts_v1.insertOne({
    _id: "post1",
    title: "Mon article de blog",
    content: "Contenu de l'article...",
    comments: comments
})
```

**√âtape 2 : Mesurer la taille du document**

```javascript
const post = db.posts_v1.findOne({_id: "post1"})
Object.bsonsize(post)
```

üìù **Question 1 :** Quelle est la taille en octets ? _______ bytes

**√âtape 3 : Simuler un post viral avec 2000 commentaires**

```javascript
// Ajouter 1500 commentaires suppl√©mentaires
for (let i = 500; i < 2000; i++) {
    db.posts_v1.updateOne(
        {_id: "post1"},
        {$push: {comments: {
            user: `user_${i % 100}`,
            text: `Commentaire ${i}`,
            date: new Date()
        }}}
    )
}

// Mesurer √† nouveau
const bigPost = db.posts_v1.findOne({_id: "post1"})
Object.bsonsize(bigPost)
```

üìù **Question 2 :** Quelle est la nouvelle taille ? _______ bytes

üìù **Question 3 :** Sachant que la limite MongoDB est de 16 Mo, combien de commentaires pourriez-vous avoir avant d'atteindre cette limite ? _______

**Probl√®mes identifi√©s :**
1. Document de plus en plus gros ‚Üí transfert r√©seau lent
2. Pour afficher les 10 derniers, on charge TOUS les commentaires
3. Risque d'atteindre la limite de 16 Mo

---

#### Exercice 7 : Appliquer le Pattern Subset ‚≠ê‚≠ê‚òÜ

**Objectif :** R√©soudre le probl√®me d√©couvert en Exercice 6.

**√âtape 1 : Cr√©er la nouvelle structure**

```javascript
// Cr√©er deux collections
db.posts_v2.drop()
db.comments.drop()

// Le post ne contient que les 10 derniers commentaires
db.posts_v2.insertOne({
    _id: "post1",
    title: "Mon article de blog",
    content: "Contenu de l'article...",
    comment_count: 0,
    recent_comments: []  // Maximum 10
})
```

**√âtape 2 : Fonction pour ajouter un commentaire**

```javascript
// Fonction qui ajoute un commentaire et maintient le subset
function addComment(postId, comment) {
    // 1. Ins√©rer dans la collection comments
    const commentDoc = {
        post_id: postId,
        ...comment,
        date: new Date()
    }
    db.comments.insertOne(commentDoc)

    // 2. Mettre √† jour le post (garder seulement les 10 derniers)
    db.posts_v2.updateOne(
        {_id: postId},
        {
            $inc: {comment_count: 1},
            $push: {
                recent_comments: {
                    $each: [commentDoc],
                    $position: 0,    // Ajouter au d√©but
                    $slice: 10       // Garder seulement 10
                }
            }
        }
    )
}
```

**√âtape 3 : Tester avec 50 commentaires**

```javascript
// Ajouter 50 commentaires
for (let i = 0; i < 50; i++) {
    addComment("post1", {
        user: `user_${i}`,
        text: `Commentaire num√©ro ${i}`
    })
}

// V√©rifier le post
const post = db.posts_v2.findOne({_id: "post1"})
print("Nombre dans recent_comments:", post.recent_comments.length)
print("Compteur total:", post.comment_count)
Object.bsonsize(post)
```

üìù **Question 1 :** Combien de commentaires sont dans `recent_comments` ? _______

üìù **Question 2 :** Quelle est la taille du document ? _______

**√âtape 4 : Comparer les performances**

```javascript
// Requ√™te sur v1 (tout dans le document)
db.posts_v1.find({_id: "post1"}).explain("executionStats").executionStats.totalDocsExamined

// Requ√™te sur v2 (subset)
db.posts_v2.find({_id: "post1"}).explain("executionStats").executionStats.totalDocsExamined
```

üìù **Question 3 :** Les deux examinent 1 document, mais lequel transf√®re moins de donn√©es ? _______

**B√©n√©fices du Pattern Subset :**
| Aspect | Sans Subset (v1) | Avec Subset (v2) |
|--------|------------------|------------------|
| Taille document | ~180 Ko | ~1.5 Ko |
| Transfert r√©seau | 180 Ko | 1.5 Ko |
| Limite 16 Mo | Risque | Jamais |


---

#### Exercice 8 : Appliquer le Pattern Computed ‚≠ê‚≠ê‚òÜ

**Objectif :** √âviter de recalculer les statistiques √† chaque requ√™te.

**√âtape 1 : Observer le probl√®me**

```javascript
db.products.drop()

// Cr√©er un produit avec des avis
db.products.insertOne({
    _id: "prod1",
    name: "Laptop Gaming",
    price: 1299,
    reviews: [
        {user: "alice", rating: 5, text: "Excellent!"},
        {user: "bob", rating: 4, text: "Tr√®s bien"},
        {user: "carol", rating: 5, text: "Parfait"},
        {user: "dave", rating: 3, text: "Correct"},
        {user: "eve", rating: 5, text: "Super"}
    ]
})

// Calculer la moyenne avec agr√©gation
db.products.aggregate([
    {$match: {_id: "prod1"}},
    {$unwind: "$reviews"},
    {$group: {
        _id: "$_id",
        avg_rating: {$avg: "$reviews.rating"},
        count: {$sum: 1}
    }}
])
```

üìù **Question 1 :** Cette agr√©gation doit √™tre ex√©cut√©e √† chaque affichage de la page produit. Est-ce efficace ? _______

**√âtape 2 : Appliquer le Pattern Computed**

```javascript
db.products_v2.drop()

// Structure avec statistiques pr√©-calcul√©es
db.products_v2.insertOne({
    _id: "prod1",
    name: "Laptop Gaming",
    price: 1299,

    // Pattern Computed : stats pr√©-calcul√©es
    stats: {
        review_count: 5,
        rating_sum: 22,
        rating_avg: 4.4,
        rating_distribution: {5: 3, 4: 1, 3: 1, 2: 0, 1: 0}
    },

    // Pattern Subset : derniers avis seulement
    recent_reviews: [
        {user: "eve", rating: 5, text: "Super", date: new Date()}
    ]
})
```

**√âtape 3 : Fonction pour ajouter un avis**

```javascript
function addReview(productId, review) {
    db.products_v2.updateOne(
        {_id: productId},
        [
            {$set: {
                // Mettre √† jour les stats
                "stats.review_count": {$add: ["$stats.review_count", 1]},
                "stats.rating_sum": {$add: ["$stats.rating_sum", review.rating]},
                "stats.rating_avg": {
                    $divide: [
                        {$add: ["$stats.rating_sum", review.rating]},
                        {$add: ["$stats.review_count", 1]}
                    ]
                },
                // Incr√©menter la distribution
                [`stats.rating_distribution.${review.rating}`]: {
                    $add: [{$ifNull: [`$stats.rating_distribution.${review.rating}`, 0]}, 1]
                }
            }}
        ]
    )
}

// Tester
addReview("prod1", {user: "frank", rating: 4, text: "Bien!"})
db.products_v2.findOne({_id: "prod1"}).stats
```

üìù **Question 2 :** Apr√®s l'ajout, quelle est la nouvelle moyenne ? _______

üìù **Question 3 :** Combien de requ√™tes faut-il pour afficher la moyenne sur la page produit maintenant ? _______

<details>
<summary>üí° R√©ponses</summary>

- **Question 1 :** Non, l'agr√©gation est co√ªteuse et refaite √† chaque affichage
- **Question 2 :** (22 + 4) / 6 = 4.33
- **Question 3 :** Une seule requ√™te `findOne()` suffit !
</details>

**Pattern Computed :**
| Op√©ration | Sans Computed | Avec Computed |
|-----------|---------------|---------------|
| Afficher moyenne | Agr√©gation | Simple lecture |
| Ajouter avis | Insert simple | Insert + Update stats |
| Complexit√© lecture | O(n) | O(1) |

---

#### Exercice 9 : Appliquer le Pattern Bucket (S√©ries temporelles) ‚≠ê‚≠ê‚≠ê

**Objectif :** Optimiser le stockage de donn√©es IoT.

**√âtape 1 : Approche na√Øve - un document par mesure**

```javascript
db.sensor_v1.drop()

// Simuler 24h de mesures (1 mesure toutes les 5 minutes = 288 mesures)
for (let i = 0; i < 288; i++) {
    db.sensor_v1.insertOne({
        sensor_id: "ENV-001",
        timestamp: new Date(Date.now() - (287 - i) * 5 * 60000),
        temperature: 20 + Math.random() * 5,
        humidity: 45 + Math.random() * 10
    })
}

print("Documents cr√©√©s:", db.sensor_v1.countDocuments())
```

üìù **Question 1 :** Combien de documents pour 1 capteur sur 1 an ? _______

**√âtape 2 : Pattern Bucket - grouper par heure**

```javascript
db.sensor_v2.drop()

// Cr√©er des buckets horaires
function createHourlyBucket(sensorId, hour) {
    return {
        sensor_id: sensorId,
        bucket_start: hour,
        bucket_type: "hourly",
        samples: [],
        stats: {
            count: 0,
            temp_min: null,
            temp_max: null,
            temp_sum: 0
        }
    }
}

// Ajouter une mesure dans un bucket
function addMeasurement(sensorId, measurement) {
    const hour = new Date(measurement.timestamp)
    hour.setMinutes(0, 0, 0)

    db.sensor_v2.updateOne(
        {sensor_id: sensorId, bucket_start: hour},
        {
            $push: {samples: {
                t: measurement.timestamp.getMinutes(),
                temp: measurement.temperature,
                hum: measurement.humidity
            }},
            $inc: {"stats.count": 1, "stats.temp_sum": measurement.temperature},
            $min: {"stats.temp_min": measurement.temperature},
            $max: {"stats.temp_max": measurement.temperature},
            $setOnInsert: {bucket_type: "hourly"}
        },
        {upsert: true}
    )
}

// Ins√©rer les m√™mes donn√©es avec buckets
for (let i = 0; i < 288; i++) {
    addMeasurement("ENV-001", {
        timestamp: new Date(Date.now() - (287 - i) * 5 * 60000),
        temperature: 20 + Math.random() * 5,
        humidity: 45 + Math.random() * 10
    })
}

print("Buckets cr√©√©s:", db.sensor_v2.countDocuments())
```

üìù **Question 2 :** Combien de buckets pour 24h ? _______

üìù **Question 3 :** Combien de documents pour 1 capteur sur 1 an avec les buckets ? _______

**√âtape 3 : Comparer les performances**

```javascript
// Requ√™te : temp√©rature moyenne des derni√®res 24h

// V1 : Agr√©gation sur 288 documents
db.sensor_v1.aggregate([
    {$match: {sensor_id: "ENV-001"}},
    {$group: {_id: null, avg_temp: {$avg: "$temperature"}}}
]).explain("executionStats").executionStats.totalDocsExamined

// V2 : Lecture de 24 buckets avec stats pr√©-calcul√©es
db.sensor_v2.find({sensor_id: "ENV-001"}).forEach(b => {
    print(`Bucket ${b.bucket_start.getHours()}h: avg = ${(b.stats.temp_sum / b.stats.count).toFixed(2)}`)
})
```

<details>
<summary>üí° R√©ponses</summary>

- **Question 1 :** 288 √ó 365 = **105 120 documents** par capteur par an
- **Question 2 :** **24 buckets** (1 par heure)
- **Question 3 :** 24 √ó 365 = **8 760 documents** (12√ó moins !)

**Comparaison Pattern Bucket :**
| M√©trique | Sans Bucket | Avec Bucket | Gain |
|----------|-------------|-------------|------|
| Docs/jour | 288 | 24 | **12√ó moins** |
| Docs/an | 105 120 | 8 760 | **12√ó moins** |
| Requ√™te 24h | 288 docs | 24 docs | **12√ó plus rapide** |
| Stats int√©gr√©es | Non | Oui | Pas d'agr√©gation |

</details>

---

#### Exercice 10 : Synth√®se - Combiner les patterns ‚≠ê‚≠ê‚≠ê

**Contexte :** Un capteur environnemental pour la ville.

**Votre mission :** Concevoir le mod√®le de donn√©es en utilisant :
- **Bucket** pour les mesures (group√©es par heure)
- **Computed** pour les statistiques
- **Subset** pour les derni√®res alertes

```javascript
// Compl√©tez ce mod√®le :
{
    _id: ObjectId(),
    sensor_id: "ENV-ROTONDE-001",

    // Bucket : quelle p√©riode ?
    bucket_start: ISODate("____"),
    bucket_type: "____",

    // Les mesures (max 12 par heure si mesure toutes les 5 min)
    samples: [
        // Quel format pour chaque mesure ?
    ],

    // Computed : quelles stats pr√©-calculer ?
    stats: {
        // ...
    },

    // Subset : les 3 derni√®res alertes de l'heure
    recent_alerts: [
        // ...
    ]
}
```

<details>
<summary>üí° Solution compl√®te</summary>

```javascript
{
    _id: ObjectId(),
    sensor_id: "ENV-ROTONDE-001",

    // Bucket horaire
    bucket_start: ISODate("2024-01-15T10:00:00Z"),
    bucket_type: "hourly",

    // M√©tadonn√©es (d√©normalis√©es)
    location: {
        zone: "centre-ville",
        name: "Place de la Rotonde",
        coordinates: [5.4474, 43.5263]
    },

    // Mesures compact√©es (t = offset en minutes)
    samples: [
        {t: 0,  temp: 22.3, hum: 45, co2: 405, pm25: 12.1},
        {t: 5,  temp: 22.5, hum: 45, co2: 410, pm25: 12.3},
        {t: 10, temp: 22.4, hum: 46, co2: 408, pm25: 12.0}
        // ... jusqu'√† 12 mesures par heure
    ],

    // Stats pr√©-calcul√©es (Pattern Computed)
    stats: {
        count: 3,
        temperature: {min: 22.3, max: 22.5, avg: 22.4},
        humidity: {min: 45, max: 46, avg: 45.3},
        co2: {min: 405, max: 410, avg: 407.7},
        pm25: {min: 12.0, max: 12.3, avg: 12.1}
    },

    // Derni√®res alertes (Pattern Subset)
    recent_alerts: [
        {
            type: "co2_high",
            value: 410,
            threshold: 400,
            time: 5
        }
    ],
    alert_count: 1
}

// Index recommand√©s
db.sensor_buckets.createIndex({sensor_id: 1, bucket_start: -1})
db.sensor_buckets.createIndex({"location.zone": 1, bucket_start: -1})
```

**Patterns combin√©s :**

| Pattern | Application | B√©n√©fice |
|---------|-------------|----------|
| **Bucket** | 1 doc/heure au lieu de 12 | 12√ó moins de documents |
| **Computed** | Stats min/max/avg | Pas d'agr√©gation pour affichage |
| **Subset** | 3 derni√®res alertes | Alertes r√©centes sans requ√™te |
| **D√©normalisation** | Location dans chaque bucket | Pas de jointure pour filtrer par zone |

</details>

---

## üèóÔ∏è Phase 3 : Patterns architecturaux (45 min)

### Pattern : Versioning des documents

**Probl√®me :** Garder l'historique des modifications.

#### Option A : Versioning dans le document

```javascript
{
    _id: "doc123",
    version: 3,
    current: {
        title: "Version actuelle",
        content: "...",
        updated_at: ISODate("2024-01-15")
    },
    history: [
        {
            version: 2,
            title: "Ancienne version",
            content: "...",
            updated_at: ISODate("2024-01-10"),
            updated_by: "user456"
        },
        // ... versions pr√©c√©dentes
    ]
}
```

#### Option B : Collection s√©par√©e pour l'historique

```javascript
// Collection principale
{
    _id: "doc123",
    version: 3,
    title: "Version actuelle",
    content: "..."
}

// Collection historique
{
    _id: ObjectId(),
    doc_id: "doc123",
    version: 2,
    title: "Ancienne version",
    content: "...",
    updated_at: ISODate("2024-01-10")
}
```

### Pattern : Polymorphic (Polymorphe)

**Probl√®me :** Stocker diff√©rents types d'entit√©s dans une collection.

```javascript
// Collection events : diff√©rents types d'√©v√©nements
{
    _id: ObjectId(),
    type: "sensor_reading",
    timestamp: ISODate("..."),
    sensor_id: "SENS-001",
    data: {
        temperature: 22.5,
        humidity: 45
    }
}

{
    _id: ObjectId(),
    type: "alert",
    timestamp: ISODate("..."),
    severity: "high",
    message: "Temperature exceeded threshold",
    sensor_id: "SENS-001",
    threshold: 30,
    value: 32.5
}

{
    _id: ObjectId(),
    type: "maintenance",
    timestamp: ISODate("..."),
    sensor_id: "SENS-001",
    technician: "John Doe",
    actions: ["battery_replaced", "calibration"]
}

// Index partiel par type
db.events.createIndex(
    {sensor_id: 1, timestamp: -1},
    {partialFilterExpression: {type: "sensor_reading"}}
)
```

### Pattern : CQRS (Command Query Responsibility Segregation)

**Probl√®me :** Mod√®les optimaux diff√©rents pour lecture vs √©criture.

#### Architecture CQRS pour IoT

```mermaid
flowchart TB
    subgraph Commands ["‚¨áÔ∏è COMMANDS (√âcriture)"]
        C1[API Ingestion] --> C2[(sensor_writes)]
        C2 --> C3[Change Stream]
    end

    subgraph Sync ["üîÑ SYNCHRONISATION"]
        C3 --> S1[Event Handler]
        S1 --> S2[Transformer]
    end

    subgraph Queries ["‚¨ÜÔ∏è QUERIES (Lecture)"]
        S2 --> Q1[(current_state<br/>Vue temps r√©el)]
        S2 --> Q2[(hourly_buckets<br/>Vue agr√©g√©e)]
        S2 --> Q3[(alerts<br/>Vue alertes)]

        Q1 --> R1[Dashboard]
        Q2 --> R2[Graphiques]
        Q3 --> R3[Notifications]
    end

    style Commands fill:#e8f5e9
    style Queries fill:#e3f2fd
    style Sync fill:#fff3e0
```

```javascript
// √âCRITURE : Collection optimis√©e pour les insertions
db.sensor_writes.insertOne({
    sensor_id: "SENS-001",
    timestamp: new Date(),
    temperature: 22.5,
    humidity: 45,
    co2: 410
})

// LECTURE : Collections optimis√©es pour les requ√™tes
// Mise √† jour par batch ou change streams

// Vue 1 : Derni√®res valeurs par capteur
db.sensor_current.findOne({_id: "SENS-001"})
// {
//     _id: "SENS-001",
//     location: {...},
//     last_reading: {...},
//     status: "online"
// }

// Vue 2 : Agr√©gations horaires
db.sensor_hourly.find({
    sensor_id: "SENS-001",
    hour: ISODate("2024-01-15T10:00:00Z")
})

// Synchronisation avec Change Streams
const pipeline = [
    {$match: {operationType: "insert"}}
];

db.sensor_writes.watch(pipeline).on("change", (change) => {
    // Mettre √† jour les vues de lecture
    updateCurrentView(change.fullDocument);
    updateHourlyView(change.fullDocument);
});
```

### Pattern : Archive

**Probl√®me :** Donn√©es anciennes rarement acc√©d√©es mais √† conserver.

#### Cycle de vie des donn√©es IoT

```mermaid
flowchart LR
    subgraph Hot ["üî• HOT (7 jours)"]
        A[(raw_measurements)]
    end

    subgraph Warm ["üå°Ô∏è WARM (90 jours)"]
        B[(hourly_buckets)]
    end

    subgraph Cold ["‚ùÑÔ∏è COLD (1 an)"]
        C[(daily_summary)]
    end

    subgraph Archive ["üì¶ ARCHIVE (>1 an)"]
        D[(yearly_archive)]
        E[S3 / Cold Storage]
    end

    A -->|Agr√©gation<br/>horaire| B
    B -->|Agr√©gation<br/>journali√®re| C
    C -->|Export<br/>annuel| D
    D -->|Compression<br/>externe| E

    A -.->|TTL 7j| X1[üóëÔ∏è]
    B -.->|TTL 90j| X2[üóëÔ∏è]
    C -.->|TTL 365j| X3[üóëÔ∏è]

    style Hot fill:#ffcdd2
    style Warm fill:#ffe0b2
    style Cold fill:#b3e5fc
    style Archive fill:#e1bee7
```

| Niveau | Collection | R√©tention | Granularit√© | Usage |
|--------|------------|-----------|-------------|-------|
| **Hot** | raw_measurements | 7 jours | 5 min | Debug, alertes |
| **Warm** | hourly_buckets | 90 jours | 1 heure | Graphiques, trends |
| **Cold** | daily_summary | 1 an | 1 jour | Rapports, analytics |
| **Archive** | yearly_archive | Ind√©fini | 1 mois | Compliance, audit |

```javascript
// Collection active (derniers 30 jours)
db.measurements.insertOne({
    sensor_id: "SENS-001",
    timestamp: new Date(),
    data: {...},
    ttl_date: new Date(Date.now() + 30*24*60*60*1000)
})

// Index TTL pour expiration automatique
db.measurements.createIndex(
    {ttl_date: 1},
    {expireAfterSeconds: 0}
)

// Archivage avant suppression
const archivePipeline = [
    {$match: {
        timestamp: {$lt: new Date(Date.now() - 29*24*60*60*1000)}
    }},
    {$merge: {
        into: "measurements_archive",
        whenMatched: "replace"
    }}
];

// Cron job quotidien
db.measurements.aggregate(archivePipeline)
```

---

## üí° Phase 4 : Cas pratique IoT (50 min)

### Analyse des besoins

Votre module doit g√©rer :
- **Volume :** 1000 capteurs √ó 288 mesures/jour = 288k documents/jour
- **R√©tention :** 7 jours brut, 1 an agr√©g√©
- **Requ√™tes :** Temps r√©el, historique, alertes, analytics

### Architecture propos√©e

```mermaid
graph TB
    subgraph Ingestion
        A[Capteurs IoT] -->|MQTT/HTTP| B[API Ingestion]
    end
    
    subgraph Storage
        B --> C[raw_measurements<br/>TTL 7 jours]
        B --> D[current_state<br/>Derni√®re valeur]
        
        C --> E[hourly_buckets<br/>Pattern Bucket]
        E --> F[daily_summary<br/>Pattern Computed]
        F --> G[monthly_archive]
    end
    
    subgraph Queries
        D --> H[Dashboard<br/>Temps r√©el]
        E --> I[Graphiques<br/>24h]
        F --> J[Rapports<br/>Mensuels]
    end
```

### Impl√©mentation des collections

#### Collection 1 : raw_measurements (donn√©es brutes)

```javascript
// Insertion temps r√©el
{
    _id: ObjectId(),
    sensor_id: "SENS-001",
    timestamp: ISODate("2024-01-15T10:05:00Z"),
    
    // Donn√©es brutes
    temperature: 22.5,
    humidity: 45.2,
    co2: 410,
    pm25: 12.3,
    
    // M√©tadonn√©es
    quality_score: 0.98,  // Qualit√© du signal
    battery_level: 85,
    
    // TTL pour suppression automatique
    expire_at: ISODate("2024-01-22T10:05:00Z")
}

// Index
db.raw_measurements.createIndex({sensor_id: 1, timestamp: -1})
db.raw_measurements.createIndex({expire_at: 1}, {expireAfterSeconds: 0})
```

#### Collection 2 : hourly_buckets (Pattern Bucket)

```javascript
{
    _id: {
        sensor_id: "SENS-001",
        hour: ISODate("2024-01-15T10:00:00Z")
    },
    
    // Mesures compact√©es (t = minutes depuis l'heure)
    measurements: [
        {t: 0, temp: 22.5, hum: 45.2, co2: 410, pm25: 12.3},
        {t: 5, temp: 22.6, hum: 45.1, co2: 408, pm25: 12.1},
        // ... max 12 entr√©es
    ],
    
    // Statistiques pr√©-calcul√©es
    stats: {
        count: 12,
        temperature: {
            min: 22.1, max: 23.2, avg: 22.5,
            std_dev: 0.3
        },
        humidity: {
            min: 44.8, max: 46.1, avg: 45.2
        },
        // ... autres m√©triques
    },
    
    // D√©tection d'anomalies
    anomalies: [
        {t: 25, type: "spike", metric: "co2", value: 850}
    ],
    
    updated_at: ISODate("2024-01-15T10:59:59Z")
}

// Pipeline d'agr√©gation pour cr√©er les buckets
db.raw_measurements.aggregate([
    {$match: {
        sensor_id: "SENS-001",
        timestamp: {
            $gte: ISODate("2024-01-15T10:00:00Z"),
            $lt: ISODate("2024-01-15T11:00:00Z")
        }
    }},
    {$group: {
        _id: {
            sensor_id: "$sensor_id",
            hour: {$dateTrunc: {date: "$timestamp", unit: "hour"}}
        },
        measurements: {
            $push: {
                t: {$minute: "$timestamp"},
                temp: "$temperature",
                hum: "$humidity",
                co2: "$co2",
                pm25: "$pm25"
            }
        },
        // Calculer les stats
        temp_values: {$push: "$temperature"},
        // ...
    }},
    {$project: {
        measurements: 1,
        stats: {
            count: {$size: "$measurements"},
            temperature: {
                min: {$min: "$temp_values"},
                max: {$max: "$temp_values"},
                avg: {$avg: "$temp_values"},
                std_dev: {$stdDevPop: "$temp_values"}
            }
            // ...
        }
    }},
    {$merge: {
        into: "hourly_buckets",
        on: "_id",
        whenMatched: "replace"
    }}
])
```

#### Collection 3 : current_state (√©tat actuel)

```javascript
{
    _id: "SENS-001",  // sensor_id comme _id pour lectures rapides
    
    // Localisation
    location: {
        type: "Point",
        coordinates: [5.447427, 43.529742],
        address: "Place Rotonde, Aix-en-Provence"
    },
    
    // Derni√®re mesure
    last_reading: {
        timestamp: ISODate("2024-01-15T10:55:00Z"),
        temperature: 22.5,
        humidity: 45.2,
        co2: 410,
        pm25: 12.3
    },
    
    // √âtat et sant√©
    status: "online",  // online, offline, maintenance
    battery_level: 85,
    last_maintenance: ISODate("2024-01-01"),
    
    // Statistiques rolling window (derni√®re heure)
    last_hour_stats: {
        avg_temperature: 22.5,
        max_co2: 425,
        alert_count: 0
    },
    
    // Configuration des seuils
    thresholds: {
        temperature: {min: 15, max: 30},
        co2: {max: 1000},
        pm25: {max: 50}
    }
}
```

### Exercices

Ces exercices utilisent les collections d√©finies ci-dessus. Commencez par cr√©er les donn√©es de test.

---

#### Exercice 11 : Cr√©er et interroger les donn√©es IoT ‚≠ê‚≠ê‚òÜ

**Objectif :** Manipuler les collections IoT et comprendre leur structure.

**√âtape 1 : Cr√©er des donn√©es de test**

```javascript
// Nettoyer
db.current_state.drop()
db.raw_measurements.drop()

// Cr√©er 5 capteurs avec leur √©tat actuel
const zones = ["centre-ville", "gare", "campus", "port", "colline"]
const capteurs = []

for (let i = 1; i <= 5; i++) {
    capteurs.push({
        _id: `SENS-00${i}`,
        location: {
            zone: zones[i-1],
            coordinates: [5.44 + i*0.01, 43.52 + i*0.01]
        },
        status: i === 3 ? "offline" : "online",
        last_reading: {
            timestamp: new Date(Date.now() - (i === 3 ? 30*60000 : 5*60000)),
            temperature: 20 + i * 2 + Math.random() * 3,
            humidity: 40 + i * 5,
            co2: 380 + i * 20
        },
        battery_level: 100 - i * 10
    })
}

db.current_state.insertMany(capteurs)
print("Capteurs cr√©√©s:", db.current_state.countDocuments())
```

**√âtape 2 : Requ√™tes de base**

```javascript
// Q1 : Trouver les capteurs en ligne
db.current_state.find({status: "online"}).count()

// Q2 : Capteur avec la temp√©rature la plus √©lev√©e
db.current_state.find({status: "online"})
    .sort({"last_reading.temperature": -1})
    .limit(1)
    .toArray()

// Q3 : Capteurs avec batterie < 70%
db.current_state.find({battery_level: {$lt: 70}}, {_id: 1, battery_level: 1})
```

üìù **Question 1 :** Combien de capteurs sont en ligne ? _______

üìù **Question 2 :** Quel capteur a la temp√©rature la plus √©lev√©e ? _______

üìù **Question 3 :** Combien de capteurs ont une batterie < 70% ? _______

<details>
<summary>üí° R√©ponses</summary>

- **Q1 :** 4 capteurs (SENS-003 est offline)
- **Q2 :** SENS-005 (temp√©rature ~30-33¬∞C)
- **Q3 :** 2 capteurs (SENS-004 et SENS-005)

</details>

---

#### Exercice 12 : Agr√©gation par zone ‚≠ê‚≠ê‚òÜ

**Objectif :** Calculer des statistiques par zone g√©ographique.

**√âtape 1 : Pipeline de statistiques par zone**

```javascript
db.current_state.aggregate([
    // Filtrer les capteurs actifs
    {$match: {status: "online"}},

    // Grouper par zone
    {$group: {
        _id: "$location.zone",
        avg_temp: {$avg: "$last_reading.temperature"},
        max_temp: {$max: "$last_reading.temperature"},
        min_temp: {$min: "$last_reading.temperature"},
        avg_co2: {$avg: "$last_reading.co2"},
        sensor_count: {$sum: 1}
    }},

    // Trier par temp√©rature moyenne d√©croissante
    {$sort: {avg_temp: -1}},

    // Formater la sortie
    {$project: {
        zone: "$_id",
        _id: 0,
        avg_temp: {$round: ["$avg_temp", 1]},
        max_temp: {$round: ["$max_temp", 1]},
        avg_co2: {$round: ["$avg_co2", 0]},
        sensor_count: 1
    }}
])
```

üìù **Question 1 :** Quelle zone a la temp√©rature moyenne la plus √©lev√©e ? _______

**√âtape 2 : Ajouter une alerte sur les zones chaudes**

```javascript
db.current_state.aggregate([
    {$match: {status: "online"}},
    {$group: {
        _id: "$location.zone",
        avg_temp: {$avg: "$last_reading.temperature"},
        sensors: {$push: "$_id"}
    }},
    // Ajouter un flag d'alerte si temp > 25¬∞C
    {$addFields: {
        alert: {$cond: [{$gt: ["$avg_temp", 25]}, "‚ö†Ô∏è Zone chaude", "‚úÖ Normal"]}
    }},
    {$sort: {avg_temp: -1}}
])
```

üìù **Question 2 :** Combien de zones d√©clenchent une alerte ? _______

<details>
<summary>üí° R√©ponses</summary>

- **Q1 :** "colline" (SENS-005, temp√©rature la plus √©lev√©e)
- **Q2 :** Probablement 2-3 zones selon les valeurs al√©atoires

</details>

---

#### Exercice 13 : D√©tecter les capteurs offline ‚≠ê‚≠ê‚òÜ

**Objectif :** Identifier les capteurs qui ne r√©pondent plus.

**√âtape 1 : Requ√™te simple**

```javascript
// Capteurs offline ou sans donn√©es depuis 15 minutes
const threshold = new Date(Date.now() - 15 * 60000)

db.current_state.find({
    $or: [
        {status: "offline"},
        {"last_reading.timestamp": {$lt: threshold}}
    ]
}, {
    _id: 1,
    status: 1,
    "last_reading.timestamp": 1,
    battery_level: 1
})
```

üìù **Question 1 :** Quel(s) capteur(s) sont d√©tect√©s ? _______

**√âtape 2 : Pipeline avec calcul du temps offline**

```javascript
const now = new Date()

db.current_state.aggregate([
    // Capteurs potentiellement offline
    {$match: {
        $or: [
            {status: "offline"},
            {"last_reading.timestamp": {$lt: new Date(now - 15*60000)}}
        ]
    }},

    // Calculer le temps depuis derni√®re mesure
    {$addFields: {
        minutes_offline: {
            $round: [{$divide: [
                {$subtract: [now, "$last_reading.timestamp"]},
                60000
            ]}, 0]
        }
    }},

    // Ajouter une s√©v√©rit√©
    {$addFields: {
        severity: {
            $switch: {
                branches: [
                    {case: {$gt: ["$minutes_offline", 60]}, then: "üî¥ CRITICAL"},
                    {case: {$gt: ["$minutes_offline", 30]}, then: "üü† HIGH"},
                    {case: {$gt: ["$minutes_offline", 15]}, then: "üü° MEDIUM"}
                ],
                default: "üü¢ LOW"
            }
        }
    }},

    // Projection finale
    {$project: {
        sensor_id: "$_id",
        _id: 0,
        zone: "$location.zone",
        minutes_offline: 1,
        severity: 1,
        battery_level: 1
    }}
])
```

üìù **Question 2 :** Quelle est la s√©v√©rit√© pour SENS-003 ? _______

<details>
<summary>üí° R√©ponses</summary>

- **Q1 :** SENS-003 (status: "offline", cr√©√© avec 30 min de retard)
- **Q2 :** "üü† HIGH" (30 minutes offline)

</details>

---

#### Exercice 14 : Simuler des mesures et cr√©er des buckets ‚≠ê‚≠ê‚≠ê

**Objectif :** Appliquer le pattern Bucket sur des donn√©es IoT.

**√âtape 1 : Ins√©rer des mesures brutes**

```javascript
db.raw_measurements.drop()

// Simuler 1h de mesures pour SENS-001 (toutes les 5 min = 12 mesures)
const baseTime = new Date()
baseTime.setMinutes(0, 0, 0)  // D√©but de l'heure

for (let i = 0; i < 12; i++) {
    db.raw_measurements.insertOne({
        sensor_id: "SENS-001",
        timestamp: new Date(baseTime.getTime() + i * 5 * 60000),
        temperature: 22 + Math.sin(i/2) * 2,  // Variation sinuso√Ødale
        humidity: 45 + Math.random() * 5,
        co2: 400 + i * 5
    })
}

print("Mesures cr√©√©es:", db.raw_measurements.countDocuments())
```

**√âtape 2 : Cr√©er un bucket horaire par agr√©gation**

```javascript
db.hourly_buckets.drop()

db.raw_measurements.aggregate([
    {$match: {sensor_id: "SENS-001"}},

    // Grouper par heure
    {$group: {
        _id: {
            sensor_id: "$sensor_id",
            hour: {$dateTrunc: {date: "$timestamp", unit: "hour"}}
        },
        // Collecter les mesures
        measurements: {$push: {
            t: {$minute: "$timestamp"},
            temp: {$round: ["$temperature", 1]},
            hum: {$round: ["$humidity", 1]},
            co2: "$co2"
        }},
        // Calculer les stats
        count: {$sum: 1},
        temp_min: {$min: "$temperature"},
        temp_max: {$max: "$temperature"},
        temp_avg: {$avg: "$temperature"},
        co2_max: {$max: "$co2"}
    }},

    // Reformater
    {$project: {
        _id: 1,
        measurements: 1,
        stats: {
            count: "$count",
            temperature: {
                min: {$round: ["$temp_min", 1]},
                max: {$round: ["$temp_max", 1]},
                avg: {$round: ["$temp_avg", 1]}
            },
            co2_max: "$co2_max"
        }
    }},

    // Sauvegarder
    {$merge: {into: "hourly_buckets", whenMatched: "replace"}}
])

// V√©rifier
db.hourly_buckets.findOne()
```

üìù **Question 1 :** Combien de mesures dans le bucket ? _______

üìù **Question 2 :** Comparez : 12 documents raw vs 1 bucket. Quel gain ? _______

<details>
<summary>üí° R√©ponses</summary>

- **Q1 :** 12 mesures
- **Q2 :** Gain de 12√ó en nombre de documents, plus les stats pr√©-calcul√©es !

</details>

---

#### Exercice 15 : Synth√®se - Dashboard temps r√©el ‚≠ê‚≠ê‚≠ê

**Objectif :** Cr√©er une vue agr√©g√©e pour un dashboard.

```javascript
// Pipeline complet pour dashboard
db.current_state.aggregate([
    // Statistiques globales
    {$facet: {
        // Vue 1 : R√©sum√© g√©n√©ral
        summary: [
            {$group: {
                _id: null,
                total_sensors: {$sum: 1},
                online: {$sum: {$cond: [{$eq: ["$status", "online"]}, 1, 0]}},
                avg_temp: {$avg: "$last_reading.temperature"},
                avg_battery: {$avg: "$battery_level"}
            }},
            {$project: {_id: 0}}
        ],

        // Vue 2 : Top 3 temp√©ratures
        hottest: [
            {$match: {status: "online"}},
            {$sort: {"last_reading.temperature": -1}},
            {$limit: 3},
            {$project: {
                sensor: "$_id",
                zone: "$location.zone",
                temp: {$round: ["$last_reading.temperature", 1]}
            }}
        ],

        // Vue 3 : Alertes batterie
        low_battery: [
            {$match: {battery_level: {$lt: 50}}},
            {$project: {
                sensor: "$_id",
                battery: "$battery_level"
            }}
        ]
    }}
])
```

üìù **Question :** Cette requ√™te retourne combien de vues diff√©rentes ? _______

<details>
<summary>üí° R√©ponse</summary>

3 vues : `summary`, `hottest`, et `low_battery` - gr√¢ce √† `$facet` qui permet d'ex√©cuter plusieurs pipelines en parall√®le sur les m√™mes donn√©es.

</details>

---

## üîß Phase 5 : Optimisation et bonnes pratiques (30 min)

Cette phase couvre les techniques essentielles pour passer d'un prototype fonctionnel √† un syst√®me de production performant. En IoT, o√π les volumes de donn√©es sont importants et la latence critique, ces optimisations font souvent la diff√©rence entre un syst√®me utilisable et un syst√®me qui s'effondre sous la charge.

---

### Strat√©gies d'indexation

#### Pourquoi les index sont cruciaux en IoT ?

Sans index, MongoDB doit parcourir **tous les documents** (collection scan) pour trouver ceux qui correspondent √† votre requ√™te. Avec 1 000 capteurs √©mettant une mesure toutes les 5 minutes, vous aurez **288 000 documents par jour**, soit **8,6 millions par mois**.

| Situation | Sans index | Avec index appropri√© |
|-----------|-----------|---------------------|
| Requ√™te sur 1 capteur | Scan 8.6M docs | ~12 docs lus |
| Temps de r√©ponse | 2-5 secondes | < 10 ms |
| Impact CPU | √âlev√© (100%) | Minimal |

#### La r√®gle ESR : Equality, Sort, Range

L'ordre des champs dans un index compos√© est **crucial**. MongoDB ne peut utiliser efficacement un index que si les champs sont ordonn√©s selon le pattern **ESR** :

1. **E**quality (√©galit√©) : `{field: value}` - Les champs avec des conditions d'√©galit√© en premier
2. **S**ort (tri) : `sort({field: 1})` - Les champs de tri ensuite
3. **R**ange (plage) : `{field: {$gte: x}}` - Les champs avec des plages en dernier

```javascript
// Requ√™te typique IoT : "les mesures du capteur X entre deux dates, tri√©es par date"
db.measurements.find({
    sensor_id: "temp_zone_A",           // E: Equality
    timestamp: {$gte: dateDebut, $lte: dateFin}  // R: Range
}).sort({timestamp: -1})                // S: Sort

// ‚úÖ Index optimal (ESR)
db.measurements.createIndex({sensor_id: 1, timestamp: -1})
// Pourquoi √ßa marche :
// 1. MongoDB trouve directement sensor_id = "temp_zone_A" (Equality)
// 2. Dans ce sous-ensemble, les docs sont d√©j√† tri√©s par timestamp (Sort + Range)
// ‚Üí Lecture s√©quentielle tr√®s efficace

// ‚ùå Index invers√© (mauvais ordre)
db.measurements.createIndex({timestamp: -1, sensor_id: 1})
// Pourquoi c'est mauvais :
// 1. MongoDB parcourt TOUS les timestamps r√©cents (millions de docs)
// 2. Pour chaque timestamp, il filtre sur sensor_id
// ‚Üí Beaucoup plus de lectures n√©cessaires
```

#### Index partiels : √©conomiser l'espace intelligemment

Un index partiel n'indexe que les documents qui correspondent √† une condition. C'est id√©al pour les alertes, qui ne concernent qu'une minorit√© de mesures :

```javascript
// Probl√®me : 99% des mesures sont normales, 1% sont des alertes
// Un index complet sur "alert" gaspille de l'espace

// Solution : indexer uniquement les documents avec alerte
db.measurements.createIndex(
    {sensor_id: 1, alert_level: 1, timestamp: -1},
    {partialFilterExpression: {alert_level: {$exists: true}}}
)

// ‚ö†Ô∏è Attention : cette requ√™te N'UTILISE PAS l'index partiel
db.measurements.find({sensor_id: "temp_01"})  // pas de filtre sur alert_level

// ‚úÖ Cette requ√™te utilise l'index partiel
db.measurements.find({sensor_id: "temp_01", alert_level: "critical"})
```

#### Index TTL : nettoyage automatique des donn√©es

En IoT, on garde souvent les donn√©es d√©taill√©es pendant une p√©riode limit√©e (ex: 30 jours) puis on ne conserve que les agr√©gats. L'index TTL supprime automatiquement les documents expir√©s :

```javascript
// Option 1 : Expiration apr√®s une dur√©e fixe depuis la cr√©ation
db.raw_measurements.createIndex(
    {created_at: 1},
    {expireAfterSeconds: 2592000}  // 30 jours en secondes
)
// ‚ö†Ô∏è Le champ DOIT √™tre de type Date

// Option 2 : Expiration √† une date pr√©cise (plus flexible)
db.measurements.createIndex(
    {expire_at: 1},
    {expireAfterSeconds: 0}  // 0 = expirer exactement √† la date indiqu√©e
)

// Insertion avec date d'expiration personnalis√©e par capteur
db.measurements.insertOne({
    sensor_id: "temp_zone_A",
    value: 22.5,
    timestamp: new Date(),
    // Les capteurs critiques gardent les donn√©es plus longtemps
    expire_at: new Date(Date.now() + 90 * 24 * 60 * 60 * 1000)  // 90 jours
})
```

> üí° **Conseil** : Le processus TTL s'ex√©cute toutes les 60 secondes. Ne comptez pas sur une suppression √† la seconde pr√®s.

---

### Patterns de mise √† jour efficaces

#### Pourquoi les mises √† jour atomiques sont essentielles ?

En IoT, plusieurs sources peuvent tenter de modifier le m√™me document simultan√©ment :
- Plusieurs mesures arrivent pour le m√™me capteur
- Un processus met √† jour les statistiques pendant qu'un autre ins√®re des donn√©es
- Des workers parall√®les traitent des √©v√©nements en concurrence

MongoDB garantit l'atomicit√© au niveau du document, mais des conflits peuvent survenir.

#### Pattern Upsert avec gestion des conflits

```javascript
// Probl√®me : mise √† jour de l'√©tat courant d'un capteur
// Deux mesures arrivent quasi-simultan√©ment pour le m√™me capteur

// ‚ùå Approche na√Øve (race condition possible)
const doc = await db.current_state.findOne({sensor_id: "temp_01"})
if (doc) {
    await db.current_state.updateOne(
        {sensor_id: "temp_01"},
        {$set: {last_value: 25.5}}
    )
} else {
    await db.current_state.insertOne({sensor_id: "temp_01", last_value: 25.5})
}
// ‚ö†Ô∏è Entre findOne et updateOne, un autre processus peut ins√©rer le document
// ‚Üí Erreur duplicate key ou donn√©es perdues

// ‚úÖ Approche atomique avec upsert
await db.current_state.updateOne(
    {sensor_id: "temp_01"},
    {
        $set: {
            last_value: 25.5,
            last_update: new Date()
        },
        $inc: {update_count: 1},
        $setOnInsert: {
            created_at: new Date(),
            sensor_type: "temperature"
        }
    },
    {upsert: true}  // Cr√©e le document s'il n'existe pas
)
// $setOnInsert ne s'applique QUE lors de la cr√©ation
```

#### Pattern Retry avec backoff exponentiel

M√™me avec upsert, des conflits peuvent survenir (erreur 11000 = duplicate key). Une strat√©gie de retry robuste est essentielle :

```javascript
async function updateWithRetry(collection, filter, update, options = {}) {
    const maxRetries = options.maxRetries || 3
    const baseDelay = options.baseDelay || 100  // ms

    for (let attempt = 0; attempt < maxRetries; attempt++) {
        try {
            return await collection.updateOne(filter, update, {upsert: true})
        } catch (error) {
            // Code 11000 = Duplicate key (conflit d'insertion)
            // Code 112 = WriteConflict (conflit de transaction)
            const isRetryable = [11000, 112].includes(error.code)

            if (isRetryable && attempt < maxRetries - 1) {
                // Backoff exponentiel : 100ms, 200ms, 400ms...
                const delay = baseDelay * Math.pow(2, attempt)
                // Ajouter du "jitter" pour √©viter les thundering herds
                const jitter = Math.random() * delay * 0.1
                await new Promise(r => setTimeout(r, delay + jitter))
                continue
            }
            throw error  // Erreur non r√©cup√©rable ou max retries atteint
        }
    }
}

// Utilisation
await updateWithRetry(
    db.current_state,
    {sensor_id: "temp_01"},
    {$set: {value: 25.5}, $inc: {count: 1}}
)
```

#### Bulk Operations : traitement par lots

Quand vous devez traiter plusieurs documents, les op√©rations bulk r√©duisent drastiquement le temps d'ex√©cution en minimisant les allers-retours r√©seau :

```javascript
// ‚ùå Inefficace : 1000 requ√™tes r√©seau s√©par√©es
for (const measurement of measurements) {
    await db.current_state.updateOne(
        {sensor_id: measurement.sensor_id},
        {$set: {last_reading: measurement}}
    )
}
// Temps : ~1000 √ó 5ms = 5 secondes

// ‚úÖ Efficace : 1 seule requ√™te bulk
const bulkOps = measurements.map(m => ({
    updateOne: {
        filter: {sensor_id: m.sensor_id},
        update: {
            $set: {last_reading: m, last_update: new Date()},
            $inc: {reading_count: 1}
        },
        upsert: true
    }
}))

const result = await db.current_state.bulkWrite(bulkOps, {
    ordered: false  // Permet l'ex√©cution parall√®le des op√©rations
})
// Temps : ~50ms pour 1000 op√©rations

console.log(`
    Ins√©r√©s: ${result.insertedCount}
    Modifi√©s: ${result.modifiedCount}
    Upserts: ${result.upsertedCount}
`)
```

> üí° **ordered: false** permet √† MongoDB d'ex√©cuter les op√©rations en parall√®le. Utilisez `ordered: true` uniquement si l'ordre d'ex√©cution est important.

---

### Monitoring et observabilit√©

#### Pourquoi monitorer ?

Un syst√®me IoT en production doit √™tre surveill√© en continu pour :
- **D√©tecter les anomalies** avant qu'elles n'impactent les utilisateurs
- **Dimensionner correctement** le stockage et les ressources
- **Identifier les goulots d'√©tranglement** avant qu'ils ne deviennent critiques

#### M√©triques essentielles √† collecter

```javascript
// Structure recommand√©e pour les m√©triques syst√®me
const systemMetrics = {
    _id: ObjectId(),
    timestamp: new Date(),
    type: "system_metrics",

    // Performance des op√©rations
    operations: {
        inserts_per_second: 1250,      // Volume d'√©criture
        queries_per_second: 450,        // Volume de lecture
        avg_insert_time_ms: 2,          // Latence d'√©criture
        avg_query_time_ms: 12,          // Latence de lecture
        slow_queries_count: 3           // Requ√™tes > 100ms
    },

    // √âtat du stockage
    storage: {
        database_size_gb: 45.2,
        index_size_gb: 8.3,
        document_count: 15234567,
        avg_document_size_bytes: 512,
        compression_ratio: 0.4          // WiredTiger compression
    },

    // Sant√© du syst√®me IoT
    iot_health: {
        active_sensors: 987,
        offline_sensors: 13,            // Alerter si > seuil
        sensors_with_errors: 5,
        oldest_unprocessed_event: ISODate("2024-01-15T09:59:45Z"),
        processing_lag_seconds: 15      // Retard de traitement
    },

    // Alertes actives
    alerts: {
        critical: 2,
        warning: 8,
        info: 45
    }
}
```

#### Vue mat√©rialis√©e pour dashboard temps r√©el

```javascript
// Cr√©er une vue qui expose l'√©tat de sant√© actuel du syst√®me
db.createView("system_health_dashboard", "system_metrics", [
    // Prendre les m√©triques les plus r√©centes
    {$match: {type: "system_metrics"}},
    {$sort: {timestamp: -1}},
    {$limit: 1},

    // Calculer les indicateurs de sant√©
    {$project: {
        _id: 0,
        last_update: "$timestamp",

        // Statut global bas√© sur plusieurs crit√®res
        overall_status: {
            $switch: {
                branches: [
                    {
                        case: {$or: [
                            {$gt: ["$iot_health.offline_sensors", 50]},
                            {$gt: ["$operations.avg_query_time_ms", 500]},
                            {$gt: ["$alerts.critical", 5]}
                        ]},
                        then: "üî¥ CRITICAL"
                    },
                    {
                        case: {$or: [
                            {$gt: ["$iot_health.offline_sensors", 20]},
                            {$gt: ["$operations.avg_query_time_ms", 100]},
                            {$gt: ["$alerts.warning", 20]}
                        ]},
                        then: "üü† DEGRADED"
                    }
                ],
                default: "üü¢ HEALTHY"
            }
        },

        // M√©triques cl√©s expos√©es
        sensors_online: {
            $subtract: ["$iot_health.active_sensors", "$iot_health.offline_sensors"]
        },
        sensors_total: "$iot_health.active_sensors",
        throughput: "$operations.inserts_per_second",
        latency_ms: "$operations.avg_query_time_ms",
        storage_used_gb: "$storage.database_size_gb",

        // D√©tails des alertes
        alerts: "$alerts"
    }}
])

// Utilisation simple depuis l'application
db.system_health_dashboard.findOne()
// Retourne un document format√© pr√™t pour l'affichage
```

#### Script de collecte des m√©triques

```javascript
// √Ä ex√©cuter p√©riodiquement (cron toutes les minutes)
async function collectSystemMetrics() {
    const stats = await db.stats()
    const serverStatus = await db.adminCommand({serverStatus: 1})

    // Compter les capteurs par √©tat
    const sensorStats = await db.current_state.aggregate([
        {$group: {
            _id: null,
            total: {$sum: 1},
            offline: {$sum: {$cond: [{$eq: ["$status", "offline"]}, 1, 0]}},
            with_errors: {$sum: {$cond: [{$gt: ["$error_count", 0]}, 1, 0]}}
        }}
    ]).toArray()

    await db.system_metrics.insertOne({
        timestamp: new Date(),
        type: "system_metrics",
        operations: {
            inserts_per_second: serverStatus.opcounters.insert,
            queries_per_second: serverStatus.opcounters.query,
            // ... autres m√©triques
        },
        storage: {
            database_size_gb: stats.dataSize / (1024**3),
            index_size_gb: stats.indexSize / (1024**3),
            document_count: stats.objects
        },
        iot_health: {
            active_sensors: sensorStats[0]?.total || 0,
            offline_sensors: sensorStats[0]?.offline || 0,
            sensors_with_errors: sensorStats[0]?.with_errors || 0
        }
    })
}
```

---

### Checklist d'optimisation pour la production

Avant de d√©ployer votre syst√®me IoT en production, v√©rifiez chaque point :

#### üìä Performance des requ√™tes
| √âl√©ment | V√©rification | Commande de diagnostic |
|---------|--------------|----------------------|
| Index appropri√©s | Chaque pattern de requ√™te a un index | `db.collection.explain().find(...)` |
| Pas de collection scan | `COLLSCAN` absent des plans d'ex√©cution | `explain("executionStats")` |
| Projections utilis√©es | Limiter les champs retourn√©s | Ajouter `{field1: 1, field2: 1}` |

```javascript
// V√©rifier qu'une requ√™te utilise un index
const explanation = db.measurements.find({
    sensor_id: "temp_01",
    timestamp: {$gte: new Date("2024-01-01")}
}).explain("executionStats")

// ‚úÖ Bon : "stage": "IXSCAN" (index scan)
// ‚ùå Mauvais : "stage": "COLLSCAN" (collection scan)
console.log(explanation.queryPlanner.winningPlan.stage)
```

#### üíæ Gestion du stockage
- [ ] **Compression WiredTiger** activ√©e (snappy par d√©faut, zstd pour meilleure compression)
- [ ] **TTL index** configur√© pour la r√©tention automatique des donn√©es
- [ ] **Strat√©gie d'archivage** d√©finie pour les donn√©es historiques
- [ ] **Monitoring de l'espace disque** avec alertes √† 70%, 85%, 95%

#### üîÑ √âcritures et concurrence
- [ ] **Bulk operations** pour les insertions multiples (batch de 1000 docs)
- [ ] **Write concern** adapt√© √† la criticit√© :
  - `{w: 1}` : Acquittement par le primary (rapide, risque de perte)
  - `{w: "majority"}` : Acquittement par la majorit√© (recommand√© production)
  - `{w: "majority", j: true}` : Avec journaling (donn√©es critiques)
- [ ] **Retry logic** avec backoff exponentiel pour les conflits

#### üåê Connexions et r√©seau
- [ ] **Connection pooling** configur√© (min: 5, max: 100 typiquement)
- [ ] **Read preference** adapt√© :
  - `primary` : Coh√©rence forte (√©critures)
  - `primaryPreferred` : Tol√©rance aux pannes
  - `secondaryPreferred` : R√©partition de charge lecture
- [ ] **Timeouts** d√©finis (connect: 10s, socket: 30s, serverSelection: 30s)

#### üìà Observabilit√©
- [ ] **M√©triques** collect√©es r√©guli√®rement
- [ ] **Alertes** configur√©es sur les seuils critiques
- [ ] **Logs** structur√©s avec niveaux appropri√©s
- [ ] **Slow query log** activ√© (seuil: 100ms)

```javascript
// Activer le profiling pour identifier les requ√™tes lentes
db.setProfilingLevel(1, {slowms: 100})

// Consulter les requ√™tes lentes
db.system.profile.find().sort({ts: -1}).limit(10)
```

---


## üéØ Auto-√©valuation

Avant de terminer ce TP, r√©pondez aux questions suivantes pour valider votre compr√©hension :

### Questions de r√©flexion

<details>
<summary>‚ùì Q1 : Pourquoi utiliser le pattern Bucket plut√¥t qu'un document par mesure ?</summary>

**R√©ponse attendue :**
- **R√©duction du nombre de documents** : 24 docs/jour au lieu de 288
- **Index plus petits** : Moins d'entr√©es √† maintenir
- **Requ√™tes plus efficaces** : Lire une heure = 1 document
- **Statistiques pr√©-calcul√©es** : Pas d'agr√©gation √† la vol√©e
- **√âconomie de stockage** : Moins d'overhead par document
</details>

<details>
<summary>‚ùì Q2 : Quand pr√©f√©rer l'embedding au r√©f√©rencement ?</summary>

**R√©ponse attendue :**
- Donn√©es toujours lues ensemble (ratio proche de 1)
- Cardinalit√© faible (1:few)
- Donn√©es rarement modifi√©es ind√©pendamment
- Taille totale du document < 16MB
- Pas besoin de requ√™ter les sous-documents s√©par√©ment
</details>

<details>
<summary>‚ùì Q3 : Comment le pattern CQRS am√©liore-t-il les performances IoT ?</summary>

**R√©ponse attendue :**
- **√âcriture optimis√©e** : Collection simple, insert rapide, pas d'index complexe
- **Lecture optimis√©e** : Vues mat√©rialis√©es adapt√©es √† chaque use case
- **Isolation** : Charge d'√©criture n'impacte pas les lectures
- **Scalabilit√©** : Possibilit√© de r√©pliquer les vues de lecture
</details>

<details>
<summary>‚ùì Q4 : Quelle est la strat√©gie d'indexation optimale pour les time-series ?</summary>

**R√©ponse attendue :**
- Index compos√© `{sensor_id: 1, timestamp: -1}` (ESR : Equality, Sort, Range)
- Index TTL sur `expire_at` pour la r√©tention automatique
- Index partiel pour les anomalies uniquement
- √âviter les index sur des champs √† haute cardinalit√© seuls
</details>

---

## ‚úÖ Checklist de validation

### Mod√©lisation
- [ ] Je sais choisir entre embedding et r√©f√©rencement
- [ ] Je connais les facteurs de d√©cision (cardinalit√©, volatilit√©, etc.)
- [ ] Je peux identifier quand utiliser chaque approche

### Design Patterns
- [ ] Pattern **Subset** pour limiter la taille des tableaux
- [ ] Pattern **Computed** pour les calculs pr√©-calcul√©s
- [ ] Pattern **Bucket** pour les s√©ries temporelles
- [ ] Pattern **Attribute** pour les sch√©mas flexibles
- [ ] Pattern **Outlier** pour les cas exceptionnels

### Patterns Architecturaux
- [ ] **Versioning** pour l'historique
- [ ] **Polymorphic** pour types multiples
- [ ] **CQRS** pour s√©parer lecture/√©criture
- [ ] **Archive** pour les donn√©es anciennes

### Optimisation
- [ ] Strat√©gies d'indexation appropri√©es
- [ ] Bulk operations et retry logic
- [ ] Monitoring et m√©triques

### Application IoT
- [ ] Mod√©lisation pour time-series
- [ ] Gestion du volume de donn√©es
- [ ] Strat√©gies d'agr√©gation
- [ ] D√©tection d'anomalies

---